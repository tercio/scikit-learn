{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Sistema de Detecção de Fraudes\n",
    "\n",
    "Teste utilizando o OneClassSVM, que é uma implementação de Support Vector Machine para Unsupervised Learning\n",
    "\n",
    "Nessa versão o teste é bem simples, utiliza só duas features e não faz tantos testes de configuração da SVM. Quero fazer uma outra versão pra comparar SVM, Logistic Regression e Neural Network. Al[em disso, usar GridSearch para teste de parâmetros etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features layout: cod.cidade, valor compra\n",
    "  - cod. cidade = 1 sp, 2 jundiai, 3 campinas, 4 sorocaba, 5 internet\n",
    "  - local: 1 shoppping, 2 posto gasolina, 3 feira livre, 4 restaurante\n",
    "  \n",
    "** Create a list for training using a random number generator **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "X = np.ones((50,2))\n",
    "\n",
    "for i in range(50):\n",
    "    X [i][0] = random.uniform(1.0,4.0)\n",
    "    X [i][1] = random.uniform(50.0,200.0)\n",
    "\n",
    "\n",
    "\n",
    "#print X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Normalize data for SVM training **\n",
    "\n",
    "This is a ** very ** important step, specially because the features are in a very different range\n",
    "\n",
    "** Nota: ** o Objeto standard, criado aqui, será utilizado abaixo, nos testes, para normalizar os dados de testes baseados nos parametros de normalização usados aqui no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "standard = preprocessing.StandardScaler().fit(X)\n",
    "df_std = standard.transform(X)\n",
    "X = df_std\n",
    "\n",
    "print type(df_std)\n",
    "print df_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(50, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "      max_iter=-1, nu=0.1, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print type(X)\n",
    "print X.shape\n",
    "\n",
    "#print X\n",
    "\n",
    "\n",
    "clsf = svm.OneClassSVM(nu=0.1,kernel='rbf',gamma=0.1)\n",
    "\n",
    "clsf.fit(X)\n",
    "\n",
    "#print \"decision function\"\n",
    "#clsf.decision_function(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake data to test values in which we want to detect as normal entries (not fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possivel fraude ?\n",
      "[[   1.0418009   101.95077594]]\n",
      "possivel fraude ?\n",
      "[[   1.01461507  170.89541811]]\n",
      "possivel fraude ?\n",
      "[[   1.09892722  131.50047767]]\n",
      "possivel fraude ?\n",
      "[[  1.0225354   95.25931847]]\n",
      "Possivelmente dentro da faixa correta: \n",
      "46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for i in range (50):\n",
    "    p1 = random.uniform(1.0,4.0)\n",
    "    p2 = random.uniform(80.0,180.0)\n",
    "    v = np.ones((1,2))\n",
    "    v[0][0] = p1\n",
    "    v[0][1] = p2\n",
    "    v = v.reshape(1,-1)\n",
    "    ori = v\n",
    "    #print v\n",
    "    \n",
    "    # reuse the same standard scaler from the training set.\n",
    "    df_std = standard.transform(v)\n",
    "    v = df_std\n",
    "    #print v\n",
    "    \n",
    "    if clsf.predict (v)[0] == 1.:\n",
    "        count = count + 1\n",
    "    else:\n",
    "        print \"possivel fraude ?\"\n",
    "        print ori\n",
    "        \n",
    "print \"Possivelmente dentro da faixa correta: \"        \n",
    "print count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake data to test values in which we want to detect as Fraud\n",
    "\n",
    "Actually, part of it, should as be detected as normal entries, as I put the values or price, starting at 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possivelmente dentro da faixa de fraude: \n",
      "47\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range (50):\n",
    "    p1 = random.uniform(1.0,8.0)\n",
    "    p2 = random.uniform(10.0,480.0)\n",
    "    v = np.ones((1,2))\n",
    "    v[0][0] = p1\n",
    "    v[0][1] = p2\n",
    "    v = v.reshape(1,-1)\n",
    "    \n",
    "    # reuse the same standard scaler from the training set.\n",
    "    df_std = standard.transform(v)\n",
    "    v = df_std\n",
    "    #print v\n",
    "    \n",
    "    if clsf.predict (v)[0] == -1.:\n",
    "        count = count + 1\n",
    "        \n",
    "print \"Possivelmente dentro da faixa de fraude: \"        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.plot(X[:,0],X[:,1],'rp')\n",
    "\n",
    "Z = clsf.decision_function(X)\n",
    "#print X[:,1] - Z\n",
    "                           \n",
    "Z = Z.reshape(X[:,1].shape)\n",
    "F = X[:,1] - Z\n",
    "F2 = X[:,0] - Z\n",
    "\n",
    "print F.shape    \n",
    "print Z.shape\n",
    "print X[:,1].shape\n",
    "F2 = F2.reshape(X[:,0].shape)\n",
    "\n",
    "#plt.contour(X[:,0],X[:,1],X[:,1] - Z)\n",
    "\n",
    "#plt.scatter(X[:,0],X[:,1])\n",
    "#plt.scatter(X[:,0],F,color='r',marker='+',linewidths=1)\n",
    "#plt.contour(X,F2,levels=[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
