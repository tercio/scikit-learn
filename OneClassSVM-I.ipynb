{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Sistema de Detecção de Fraudes\n",
    "\n",
    "Teste utilizando o OneClassSVM, que é uma implementação de Support Vector Machine para Unsupervised Learning\n",
    "\n",
    "Nessa versão o teste é bem simples, utiliza só duas features e não faz tantos testes de configuração da SVM. Quero fazer uma outra versão pra comparar SVM, Logistic Regression e Neural Network. Al[em disso, usar GridSearch para teste de parâmetros etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features layout: cod.cidade, valor compra\n",
    "  - cod. cidade = 1 sp, 2 jundiai, 3 campinas, 4 sorocaba, 5 internet\n",
    "  - local: 1 shoppping, 2 posto gasolina, 3 feira livre, 4 restaurante\n",
    "  \n",
    "** Create a list for training using a random number generator **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "X = np.ones((50,2))\n",
    "\n",
    "for i in range(50):\n",
    "    X [i][0] = random.randint(1,4)\n",
    "    X [i][1] = random.uniform(50.0,200.0)\n",
    "\n",
    "\n",
    "\n",
    "#print X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Normalize data for SVM training **\n",
    "\n",
    "This is a ** very ** important step, specially because the features are in a very different range\n",
    "\n",
    "** Nota: ** o Objeto standard, criado aqui, será utilizado abaixo, nos testes, para normalizar os dados de testes baseados nos parametros de normalização usados aqui no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "standard = preprocessing.StandardScaler().fit(X)\n",
    "df_std = standard.transform(X)\n",
    "X = df_std\n",
    "\n",
    "print type(df_std)\n",
    "print df_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(50, 2)\n",
      "[[-1.32067636  0.35590529]\n",
      " [-1.32067636  1.93958381]\n",
      " [-1.32067636  0.14219066]\n",
      " [ 1.32067636 -0.82715451]\n",
      " [-1.32067636  0.79317079]\n",
      " [-1.32067636 -0.84752768]\n",
      " [ 1.32067636 -1.45408459]\n",
      " [ 0.44022545 -0.4660429 ]\n",
      " [-1.32067636 -0.66192316]\n",
      " [-0.44022545  0.02007673]\n",
      " [-1.32067636  0.93275399]\n",
      " [ 0.44022545 -0.7698409 ]\n",
      " [-0.44022545  0.20825408]\n",
      " [ 1.32067636 -1.6558988 ]\n",
      " [ 0.44022545  1.22317445]\n",
      " [ 0.44022545 -1.4039426 ]\n",
      " [-0.44022545 -0.77549852]\n",
      " [ 0.44022545  0.67053469]\n",
      " [ 1.32067636  2.09964844]\n",
      " [-0.44022545  0.26685033]\n",
      " [-1.32067636 -0.81695165]\n",
      " [ 1.32067636  1.8775552 ]\n",
      " [ 0.44022545 -0.49608866]\n",
      " [ 0.44022545 -1.39083851]\n",
      " [ 0.44022545 -0.94636254]\n",
      " [ 0.44022545 -0.79062028]\n",
      " [ 0.44022545  1.54781522]\n",
      " [-0.44022545  0.49158328]\n",
      " [-0.44022545  1.48826302]\n",
      " [ 0.44022545  0.11572328]\n",
      " [-1.32067636  0.22189817]\n",
      " [-1.32067636  0.47704623]\n",
      " [ 0.44022545  0.09947795]\n",
      " [-1.32067636  1.78998367]\n",
      " [ 1.32067636 -0.25417674]\n",
      " [ 1.32067636 -0.81546169]\n",
      " [ 1.32067636  0.14506869]\n",
      " [-0.44022545  0.39250621]\n",
      " [-1.32067636  1.35670953]\n",
      " [-0.44022545 -0.50415132]\n",
      " [ 0.44022545 -0.50875927]\n",
      " [-1.32067636 -0.74543501]\n",
      " [-1.32067636 -0.65875504]\n",
      " [ 1.32067636 -1.56060776]\n",
      " [ 0.44022545 -0.74735014]\n",
      " [-0.44022545 -0.82695351]\n",
      " [ 1.32067636  1.15268942]\n",
      " [ 0.44022545  1.33813824]\n",
      " [ 1.32067636 -0.63428973]\n",
      " [ 1.32067636 -0.58788588]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "      max_iter=-1, nu=0.1, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print type(X)\n",
    "print X.shape\n",
    "\n",
    "print X\n",
    "\n",
    "\n",
    "clsf = svm.OneClassSVM(nu=0.1,kernel='rbf',gamma=0.1)\n",
    "\n",
    "clsf.fit(X)\n",
    "\n",
    "#print \"decision function\"\n",
    "#clsf.decision_function(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake data to test values in which we want to detect as normal entries (not fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possivel fraude ?\n",
      "[[  1.          83.37285077]]\n",
      "possivel fraude ?\n",
      "[[  1.         80.1019022]]\n",
      "possivel fraude ?\n",
      "[[  1.          82.99516531]]\n",
      "Possivelmente dentro da faixa correta: \n",
      "47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for i in range (50):\n",
    "    p1 = random.randint(1,4)\n",
    "    p2 = random.uniform(80.0,180.0)\n",
    "    v = np.ones((1,2))\n",
    "    v[0][0] = p1\n",
    "    v[0][1] = p2\n",
    "    v = v.reshape(1,-1)\n",
    "    ori = v\n",
    "    #print v\n",
    "    \n",
    "    # reuse the same standard scaler from the training set.\n",
    "    df_std = standard.transform(v)\n",
    "    v = df_std\n",
    "    #print v\n",
    "    \n",
    "    if clsf.predict (v)[0] == 1.:\n",
    "        count = count + 1\n",
    "    else:\n",
    "        print \"possivel fraude ?\"\n",
    "        print ori\n",
    "        \n",
    "print \"Possivelmente dentro da faixa correta: \"        \n",
    "print count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake data to test values in which we want to detect as Fraud\n",
    "\n",
    "Actually, part of it, should as be detected as normal entries, as I put the values or price, starting at 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.          217.45285909]]\n",
      "[[   5.          110.31726588]]\n",
      "[[   7.         335.1583227]]\n",
      "[[   3.          261.92633366]]\n",
      "[[   5.          147.03437317]]\n",
      "[[   1.          333.57135642]]\n",
      "[[   5.          458.59730418]]\n",
      "[[   6.          192.74798659]]\n",
      "[[   1.         290.0351126]]\n",
      "[[  8.          64.04866038]]\n",
      "[[   8.          446.45624661]]\n",
      "[[   8.          301.95484215]]\n",
      "[[   6.          342.24731587]]\n",
      "[[   5.          233.99732097]]\n",
      "[[   7.          458.09589789]]\n",
      "[[   7.          159.85352813]]\n",
      "[[   5.          134.83715733]]\n",
      "[[  7.          89.17908957]]\n",
      "[[   8.          323.18498789]]\n",
      "[[   2.          327.12857782]]\n",
      "[[   7.          280.51939526]]\n",
      "[[   3.          303.82949335]]\n",
      "[[   3.         475.1970891]]\n",
      "[[   1.         223.5667004]]\n",
      "[[   4.         232.4886499]]\n",
      "[[   5.          446.61442737]]\n",
      "[[   6.          391.40251912]]\n",
      "[[   7.          366.84293969]]\n",
      "[[   3.          264.16449645]]\n",
      "[[   3.        354.591501]]\n",
      "[[   6.          283.28009787]]\n",
      "[[   4.          342.17077757]]\n",
      "[[   8.          321.49603327]]\n",
      "[[   3.          262.75083234]]\n",
      "[[  7.         70.1974972]]\n",
      "[[   1.          289.00994641]]\n",
      "[[  1.          62.08136229]]\n",
      "[[   2.          379.27615907]]\n",
      "[[   7.         458.5904235]]\n",
      "[[   6.          403.42107026]]\n",
      "[[   2.          407.08555144]]\n",
      "[[   8.          463.09682453]]\n",
      "[[  7.          53.54060257]]\n",
      "[[   1.          345.97235068]]\n",
      "[[   1.          238.59706091]]\n",
      "Possivelmente dentro da faixa de fraude: \n",
      "45\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range (50):\n",
    "    p1 = random.randint(1,8)\n",
    "    p2 = random.uniform(10.0,480.0)\n",
    "    v = np.ones((1,2))\n",
    "    v[0][0] = p1\n",
    "    v[0][1] = p2\n",
    "    v = v.reshape(1,-1)\n",
    "    ori = v\n",
    "    # reuse the same standard scaler from the training set.\n",
    "    df_std = standard.transform(v)\n",
    "    v = df_std\n",
    "    #print v\n",
    "    \n",
    "    if clsf.predict (v)[0] == -1.:\n",
    "        print ori\n",
    "        count = count + 1\n",
    "        \n",
    "print \"Possivelmente dentro da faixa de fraude: \"        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.plot(X[:,0],X[:,1],'rp')\n",
    "\n",
    "Z = clsf.decision_function(X)\n",
    "#print X[:,1] - Z\n",
    "                           \n",
    "Z = Z.reshape(X[:,1].shape)\n",
    "F = X[:,1] - Z\n",
    "F2 = X[:,0] - Z\n",
    "\n",
    "print F.shape    \n",
    "print Z.shape\n",
    "print X[:,1].shape\n",
    "F2 = F2.reshape(X[:,0].shape)\n",
    "\n",
    "#plt.contour(X[:,0],X[:,1],X[:,1] - Z)\n",
    "\n",
    "#plt.scatter(X[:,0],X[:,1])\n",
    "#plt.scatter(X[:,0],F,color='r',marker='+',linewidths=1)\n",
    "#plt.contour(X,F2,levels=[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
